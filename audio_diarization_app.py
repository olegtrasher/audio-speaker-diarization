# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import os
from pathlib import Path
import io
import logging
from datetime import datetime
from typing import Optional, List, Dict, Any
import tempfile
import shutil
import time
import torch
import torchaudio
from pyannote.audio import Pipeline
from pyannote.core import Annotation, Segment
import plotly.express as px
import plotly.graph_objects as go
from config import Config, check_huggingface_token, check_system_requirements

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.set_page_config(
    page_title="AudioQA - –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ",
    page_icon="üéµ",
    layout="wide",
    initial_sidebar_state="expanded"
)

class SMPTETimeCode:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å SMPTE 59.94 Drop Frame —Ç–∞–π–º–∫–æ–¥–∞–º–∏"""
    
    @staticmethod
    def seconds_to_smpte(seconds: float, start_timecode: str = "00;00;00;00") -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å–µ–∫—É–Ω–¥ –≤ SMPTE 59.94 DROP —Ç–∞–π–º–∫–æ–¥"""
        # –ü–∞—Ä—Å–∏–º –Ω–∞—á–∞–ª—å–Ω—ã–π —Ç–∞–π–º–∫–æ–¥
        start_frames = SMPTETimeCode.smpte_to_frames(start_timecode)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å–µ–∫—É–Ω–¥—ã –≤ –∫–∞–¥—Ä—ã (59.94 fps)
        total_frames = int(seconds * 59.94) + start_frames
        
        return SMPTETimeCode.frames_to_smpte(total_frames)
    
    @staticmethod
    def smpte_to_seconds(timecode: str, start_timecode: str = "00;00;00;00") -> float:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è SMPTE —Ç–∞–π–º–∫–æ–¥–∞ –≤ —Å–µ–∫—É–Ω–¥—ã"""
        frames = SMPTETimeCode.smpte_to_frames(timecode)
        start_frames = SMPTETimeCode.smpte_to_frames(start_timecode)
        
        # –í—ã—á–∏—Ç–∞–µ–º –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–º–µ—â–µ–Ω–∏–µ
        net_frames = frames - start_frames
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–µ–∫—É–Ω–¥—ã (59.94 fps)
        return net_frames / 59.94
    
    @staticmethod
    def smpte_to_frames(timecode: str) -> int:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è SMPTE —Ç–∞–π–º–∫–æ–¥–∞ –≤ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤"""
        try:
            # –ü–∞—Ä—Å–∏–º —Ç–∞–π–º–∫–æ–¥ HH;MM;SS;FF
            parts = timecode.replace(':', ';').split(';')
            if len(parts) != 4:
                return 0
                
            hours, minutes, seconds, frames = map(int, parts)
            
            # SMPTE 59.94 Drop Frame —Ä–∞—Å—á–µ—Ç
            # Drop 2 –∫–∞–¥—Ä–∞ –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É, –∫—Ä–æ–º–µ –º–∏–Ω—É—Ç –∫—Ä–∞—Ç–Ω—ã—Ö 10
            total_minutes = hours * 60 + minutes
            
            # –ë–∞–∑–æ–≤—ã–µ –∫–∞–¥—Ä—ã –±–µ–∑ —É—á–µ—Ç–∞ drop
            total_frames = (hours * 3600 + minutes * 60 + seconds) * 60 + frames
            
            # –£—á–∏—Ç—ã–≤–∞–µ–º drop frame: -2 –∫–∞–¥—Ä–∞ –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É, +2 –∫–∞–¥—Ä–∞ –∫–∞–∂–¥—ã–µ 10 –º–∏–Ω—É—Ç
            if total_minutes > 0:
                drop_frames = total_minutes * 2 - (total_minutes // 10) * 2
                total_frames -= drop_frames
            
            return max(0, total_frames)
            
        except (ValueError, IndexError):
            return 0
    
    @staticmethod
    def frames_to_smpte(total_frames: int) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∫–∞–¥—Ä–æ–≤ –≤ SMPTE 59.94 DROP —Ç–∞–π–º–∫–æ–¥"""
        if total_frames < 0:
            return "00;00;00;00"
        
        # –ö–æ–º–ø–µ–Ω—Å–∏—Ä—É–µ–º drop frame
        # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Å —É—á–µ—Ç–æ–º drop frame
        fps = 60  # –ù–æ–º–∏–Ω–∞–ª—å–Ω—ã–π FPS –¥–ª—è —Ä–∞—Å—á–µ—Ç–æ–≤
        
        # –ì—Ä—É–±—ã–π —Ä–∞—Å—á–µ—Ç –º–∏–Ω—É—Ç –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ drop –∫–∞–¥—Ä–æ–≤
        approx_total_seconds = total_frames / 59.94
        approx_total_minutes = int(approx_total_seconds / 60)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ drop –∫–∞–¥—Ä—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–º–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
        if approx_total_minutes > 0:
            drop_compensation = approx_total_minutes * 2 - (approx_total_minutes // 10) * 2
            nominal_frames = total_frames + drop_compensation
        else:
            nominal_frames = total_frames
        
        # –†–∞—Å—á–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –∏–∑ –Ω–æ–º–∏–Ω–∞–ª—å–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤
        frames = nominal_frames % fps
        total_seconds = nominal_frames // fps
        seconds = total_seconds % 60
        total_minutes = total_seconds // 60
        minutes = total_minutes % 60
        hours = total_minutes // 60
        
        return f"{hours:02d};{minutes:02d};{seconds:02d};{frames:02d}"
    
    @staticmethod
    def validate_timecode(timecode: str) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ —Ç–∞–π–º–∫–æ–¥–∞"""
        try:
            parts = timecode.replace(':', ';').split(';')
            if len(parts) != 4:
                return False
            
            hours, minutes, seconds, frames = map(int, parts)
            
            return (0 <= hours <= 23 and 
                   0 <= minutes <= 59 and 
                   0 <= seconds <= 59 and 
                   0 <= frames <= 59)
        except (ValueError, IndexError):
            return False

class AudioDiarizationApp:
    def __init__(self):
        self.pipeline = None
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º session_state –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç
        if 'df_results_original' not in st.session_state:
            st.session_state.df_results_original = None
        if 'df_results' not in st.session_state:
            st.session_state.df_results = None
        if 'start_timecode' not in st.session_state:
            st.session_state.start_timecode = "00;00;00;00"
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞
        if 'tuning_settings' not in st.session_state:
            st.session_state.tuning_settings = {
                "vad_onset": Config.DiarizationTuning.VAD_ONSET,
                "vad_offset": Config.DiarizationTuning.VAD_OFFSET,
                "seg_onset": Config.DiarizationTuning.SEGMENTATION_ONSET,
                "seg_offset": Config.DiarizationTuning.SEGMENTATION_OFFSET,
                "clustering": Config.DiarizationTuning.CLUSTERING_THRESHOLD,
                "min_speakers": Config.DiarizationTuning.MIN_SPEAKERS,
                "max_speakers": Config.DiarizationTuning.MAX_SPEAKERS,
            }
        
        self.selected_speakers = []
        
    @property
    def df_results_original(self):
        return st.session_state.df_results_original
    
    @df_results_original.setter 
    def df_results_original(self, value):
        st.session_state.df_results_original = value
        
    @property
    def df_results(self):
        return st.session_state.df_results
    
    @df_results.setter
    def df_results(self, value):
        st.session_state.df_results = value
        
    @property
    def start_timecode(self):
        return st.session_state.start_timecode
    
    @start_timecode.setter
    def start_timecode(self, value):
        st.session_state.start_timecode = value
        
    def initialize_pipeline(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏"""
        if self.pipeline is None:
            from config import Config
            
            with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏..."):
                try:
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –º–æ–¥–µ–ª—å —Å —Ç–æ–∫–µ–Ω–æ–º
                    self.pipeline = Pipeline.from_pretrained(
                        Config.DIARIZATION_MODEL,
                        use_auth_token=Config.HUGGINGFACE_TOKEN
                    )
                    st.info("üîê –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —Å —Ç–æ–∫–µ–Ω–æ–º Hugging Face")
                    
                    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
                    if Config.FORCE_GPU_USAGE:
                        if torch.cuda.is_available():
                            device = torch.device("cuda")
                            self.pipeline.to(device)
                            gpu_name = torch.cuda.get_device_name(0)
                            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                            logger.info(f"üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GPU: {gpu_name} ({gpu_memory:.1f} GB)")
                            st.success(f"üöÄ GPU –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω: {gpu_name}")
                        else:
                            logger.error("‚ùå CUDA –Ω–µ –Ω–∞–π–¥–µ–Ω! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥—Ä–∞–π–≤–µ—Ä NVIDIA, CUDA Toolkit –∏ –≤–µ—Ä—Å–∏—é PyTorch.")
                            st.error("‚ùå CUDA –Ω–µ –Ω–∞–π–¥–µ–Ω! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥—Ä–∞–π–≤–µ—Ä NVIDIA, CUDA Toolkit –∏ –≤–µ—Ä—Å–∏—é PyTorch.")
                            st.info("–í—ã–ø–æ–ª–Ω–∏—Ç–µ –≤ Python: import torch; print(torch.version.cuda); print(torch.cuda.is_available())")
                            return False
                    else:
                        st.info("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU (GPU –æ—Ç–∫–ª—é—á–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö)")
                        logger.info("CPU —Ä–µ–∂–∏–º –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")
                    
                    logger.info("–ü–∞–π–ø–ª–∞–π–Ω –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
                    return True
                    
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏: {str(e)}")
                    logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {str(e)}")
                    return False
        else:
            # –ú–æ–¥–µ–ª—å —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞
            st.info("‚úÖ –ú–æ–¥–µ–ª—å —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return True
    
    def process_audio_file(self, audio_file_path: str) -> Optional[pd.DataFrame]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ –¥–ª—è –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            file_size_mb = os.path.getsize(audio_file_path) / (1024 * 1024)
            estimated_time = max(1, int(file_size_mb * 0.5))  # –ü—Ä–∏–º–µ—Ä–Ω–æ 0.5 –º–∏–Ω—É—Ç—ã –Ω–∞ –ú–ë
            
            progress_text = f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ ({file_size_mb:.1f} –ú–ë)..."
            if file_size_mb > 50:
                progress_text += f" –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è: {estimated_time} –º–∏–Ω—É—Ç"
            
            with st.spinner(progress_text):
                # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞
                tuning = st.session_state.tuning_settings
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è
                st.info(f"üéõÔ∏è –ü—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏: VAD {tuning['vad_onset']:.2f}/{tuning['vad_offset']:.2f}, Clustering {tuning['clustering']:.3f}")
                
                # –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞ –¥–ª—è pyannote-audio 3.1+ 
                # –º–æ–≥—É—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å—Å—è —á–µ—Ä–µ–∑ API –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –±—É–¥–µ—Ç —É–ª—É—á—à–µ–Ω–∞ –≤ –±—É–¥—É—â–∏—Ö –≤–µ—Ä—Å–∏—è—Ö
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é
                diarization = self.pipeline(audio_file_path)
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ DataFrame (—Ç–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥—ã, –±–µ–∑ —Ç–∞–π–º–∫–æ–¥–æ–≤)
                results_data = []
                for turn, _, speaker in diarization.itertracks(yield_label=True):
                    results_data.append({
                        'Speaker': speaker,
                        'Start (sec)': round(turn.start, 2),
                        'End (sec)': round(turn.end, 2),
                        'Duration (sec)': round(turn.duration, 2)
                    })
                
                df = pd.DataFrame(results_data)
                
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞—á–∞–ª–∞
                df = df.sort_values('Start (sec)').reset_index(drop=True)
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –¥–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                total_segments = len(df)
                total_speakers = df['Speaker'].nunique()
                
                # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                recommendations = []
                if total_segments < 5:
                    recommendations.append("üìä –ú–∞–ª–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ - –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–∏–∑–∏—Ç—å VAD Onset –¥–æ 0.2-0.3")
                if total_speakers == 1:
                    recommendations.append("üë• –ù–∞–π–¥–µ–Ω —Ç–æ–ª—å–∫–æ 1 —Å–ø–∏–∫–µ—Ä - –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–∏–∑–∏—Ç—å Clustering –¥–æ 0.5-0.6")
                if total_speakers > 10:
                    recommendations.append("üë• –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Å–ø–∏–∫–µ—Ä–æ–≤ - –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —É–≤–µ–ª–∏—á–∏—Ç—å Clustering –¥–æ 0.8-0.9")
                
                if recommendations:
                    st.warning("üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
                    for rec in recommendations:
                        st.write(f"‚Ä¢ {rec}")
                
                logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(df)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å {df['Speaker'].nunique()} —Å–ø–∏–∫–µ—Ä–∞–º–∏")
                return df
                
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")
            return None
    
    def create_timeline_visualization(self, df: pd.DataFrame) -> go.Figure:
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–≥—Ä–∞–º–º—ã —Å–ø–∏–∫–µ—Ä–æ–≤"""
        fig = go.Figure()
        
        # –¶–≤–µ—Ç–∞ –¥–ª—è —Å–ø–∏–∫–µ—Ä–æ–≤
        colors = px.colors.qualitative.Set3
        speakers = df['Speaker'].unique()
        color_map = {speaker: colors[i % len(colors)] for i, speaker in enumerate(speakers)}
        
        for _, row in df.iterrows():
            fig.add_trace(go.Scatter(
                x=[row['Start (sec)'], row['End (sec)']],
                y=[row['Speaker'], row['Speaker']],
                mode='lines+markers',
                line=dict(color=color_map[row['Speaker']], width=8),
                showlegend=False,
                hovertemplate=f"<b>{row['Speaker']}</b><br>" +
                             f"SMPTE: {row['Start (SMPTE)']} - {row['End (SMPTE)']}<br>" +
                             f"–°–µ–∫—É–Ω–¥—ã: {row['Start (sec)']}—Å - {row['End (sec)']}—Å<br>" +
                             f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {row['Duration (sec)']}—Å<extra></extra>"
            ))
        
        fig.update_layout(
            title="–í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ —Å–ø–∏–∫–µ—Ä–æ–≤",
            xaxis_title="–í—Ä–µ–º—è (—Å–µ–∫—É–Ω–¥—ã)",
            yaxis_title="–°–ø–∏–∫–µ—Ä",
            hovermode="closest",
            height=max(400, len(speakers) * 50)
        )
        
        return fig
    
    def export_results(self, df: pd.DataFrame, output_path: str, format: str = "csv"):
        """–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª –¥–ª—è Adobe Audition"""
        try:
            if format.lower() == "csv":
                # Adobe Audition CSV —Ñ–æ—Ä–º–∞—Ç –º–∞—Ä–∫–µ—Ä–æ–≤ (TAB-separated)
                audition_data = []
                for index, row in df.iterrows():
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å–µ–∫—É–Ω–¥—ã –≤ —Ñ–æ—Ä–º–∞—Ç MM:SS.mmm –¥–ª—è Adobe Audition
                    start_seconds = row['Start (sec)']
                    duration_seconds = row['Duration (sec)']
                    
                    # –§–æ—Ä–º–∞—Ç MM:SS.mmm
                    start_minutes = int(start_seconds // 60)
                    start_secs = start_seconds % 60
                    start_time = f"{start_minutes}:{start_secs:06.3f}"
                    
                    duration_minutes = int(duration_seconds // 60)
                    duration_secs = duration_seconds % 60
                    duration_time = f"{duration_minutes}:{duration_secs:06.3f}"
                    
                    audition_data.append({
                        'Name': row['Speaker'],
                        'Start': start_time,
                        'Duration': duration_time,
                        'Time Format': 'decimal',
                        'Type': 'Cue',
                        'Description': f"{row['Speaker']} segment"
                    })
                
                audition_df = pd.DataFrame(audition_data)
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å —Ç–∞–±—É–ª—è—Ü–∏–µ–π –∫–∞–∫ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
                audition_df.to_csv(output_path, sep='\t', index=False, encoding='utf-8')
                
            elif format.lower() == "excel":
                # –î–ª—è Excel –æ—Å—Ç–∞–≤–ª—è–µ–º –æ–±—ã—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏
                export_df = df[['Speaker', 'Start (SMPTE)', 'End (SMPTE)', 'Duration (sec)']].copy()
                export_df = export_df.rename(columns={
                    'Start (SMPTE)': 'Start Timecode',
                    'End (SMPTE)': 'End Timecode',
                    'Duration (sec)': 'Duration (sec)'
                })
                export_df.to_excel(output_path, index=False)
            
            return True
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ: {str(e)}")
            return False
    
    def recalculate_timecodes(self):
        """–ü–µ—Ä–µ—Å—á–µ—Ç —Ç–∞–π–º–∫–æ–¥–æ–≤ –±–µ–∑ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        if self.df_results_original is not None:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π DataFrame —Å –ø–µ—Ä–µ—Å—á–∏—Ç–∞–Ω–Ω—ã–º–∏ —Ç–∞–π–º–∫–æ–¥–∞–º–∏
            updated_data = []
            for _, row in self.df_results_original.iterrows():
                start_tc = SMPTETimeCode.seconds_to_smpte(row['Start (sec)'], self.start_timecode)
                end_tc = SMPTETimeCode.seconds_to_smpte(row['End (sec)'], self.start_timecode)
                
                # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Å–ø–∏–∫–µ—Ä–æ–≤ –≤ Voice_XX —Ñ–æ—Ä–º–∞—Ç
                speaker_num = row['Speaker'].replace('SPEAKER_', '').replace('Speaker_', '').replace('speaker_', '')
                voice_name = f"Voice_{speaker_num}"
                
                updated_data.append({
                    'Speaker': voice_name,
                    'Start (SMPTE)': start_tc,
                    'End (SMPTE)': end_tc,
                    'Start (sec)': row['Start (sec)'],
                    'End (sec)': row['End (sec)'],
                    'Duration (sec)': row['Duration (sec)']
                })
            
            self.df_results = pd.DataFrame(updated_data)
            return True
        return False
    
    def run(self):
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
        st.title("üéµ AudioQA - –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –∞—É–¥–∏–æ")
        st.markdown("*–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∞—É–¥–∏–æ–∑–∞–ø–∏—Å–µ–π –ø–æ —Å–ø–∏–∫–µ—Ä–∞–º*")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞
        st.info("üéõÔ∏è **–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞** –¥–æ—Å—Ç—É–ø–Ω—ã –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞")
        
        # –°–∞–π–¥–±–∞—Ä —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        with st.sidebar:
            st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
            
            # –í—ã–±–æ—Ä —Ñ–∞–π–ª–∞ –Ω–∞–ø—Ä—è–º—É—é
            st.subheader("üìÅ –í—ã–±–æ—Ä —Ñ–∞–π–ª–∞")
            
            # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–ª—è file_uploader
            accepted_formats = [format.upper() for format in Config.SUPPORTED_AUDIO_FORMATS]
            
            uploaded_file = st.file_uploader(
                "–í—ã–±–µ—Ä–∏—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª",
                type=[format[1:] for format in Config.SUPPORTED_AUDIO_FORMATS],  # —É–±–∏—Ä–∞–µ–º —Ç–æ—á–∫—É –∏–∑ .wav -> wav
                help=f"–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: {', '.join(accepted_formats)}\n–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {Config.MAX_FILE_SIZE_MB} –ú–ë",
                accept_multiple_files=False
            )
            
            if uploaded_file is None:
                st.info("üëÜ –í—ã–±–µ—Ä–∏—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã")
                
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± - –≤–≤–æ–¥ –ø—É—Ç–∏ –≤—Ä—É—á–Ω—É—é
            st.subheader("üóÇÔ∏è –ò–ª–∏ —É–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å")
            manual_path = st.text_input(
                "–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É",
                placeholder="C:\\path\\to\\your\\audio\\file.wav",
                help="–ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É –Ω–∞ –≤–∞—à–µ–º –∫–æ–º–ø—å—é—Ç–µ—Ä–µ"
            )
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–æ–π —Ñ–∞–π–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
            selected_file = None
            file_path = None
            
            if uploaded_file is not None:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                file_size_mb = uploaded_file.size / (1024 * 1024)
                if file_size_mb > Config.MAX_FILE_SIZE_MB:
                    st.error(f"‚ùå –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {file_size_mb:.1f} –ú–ë (–º–∞–∫—Å. {Config.MAX_FILE_SIZE_MB} –ú–ë)")
                    return
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
                temp_dir = Path("temp")
                temp_dir.mkdir(exist_ok=True)
                
                # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (—Å—Ç–∞—Ä—à–µ 1 —á–∞—Å–∞)
                current_time = time.time()
                for old_file in temp_dir.glob("*"):
                    if old_file.is_file() and (current_time - old_file.stat().st_mtime) > 3600:
                        try:
                            old_file.unlink()
                        except:
                            pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤
                timestamp = int(time.time())
                safe_filename = f"{timestamp}_{uploaded_file.name}"
                file_path = temp_dir / safe_filename
                
                try:
                    with open(file_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    
                    selected_file = uploaded_file.name
                    st.success(f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {selected_file}")
                except Exception as e:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}")
                    return
                
            elif manual_path and os.path.exists(manual_path):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –ø—É—Ç–∏
                if any(manual_path.lower().endswith(ext) for ext in Config.SUPPORTED_AUDIO_FORMATS):
                    file_size_mb = os.path.getsize(manual_path) / (1024 * 1024)
                    if file_size_mb <= Config.MAX_FILE_SIZE_MB:
                        file_path = manual_path
                        selected_file = os.path.basename(manual_path)
                        st.success(f"‚úÖ –§–∞–π–ª –Ω–∞–π–¥–µ–Ω: {selected_file}")
                    else:
                        st.error(f"‚ùå –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {file_size_mb:.1f} –ú–ë (–º–∞–∫—Å. {Config.MAX_FILE_SIZE_MB} –ú–ë)")
                else:
                    st.error("‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞")
            elif manual_path:
                st.error("‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –ø—É—Ç–∏")
            
            # –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            st.subheader("üíª –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
            requirements, gpu_name = check_system_requirements()
            for req_name, req_status in requirements.items():
                if req_status:
                    st.success(f"‚úÖ {req_name}")
                else:
                    st.error(f"‚ùå {req_name}")
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU
            if requirements.get("GPU", False):
                st.info(f"üéÆ GPU: {gpu_name}")
                if Config.FORCE_GPU_USAGE:
                    st.info("‚ö° –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU –≤–∫–ª—é—á–µ–Ω–æ")
                else:
                    st.warning("‚ö†Ô∏è –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU –æ—Ç–∫–ª—é—á–µ–Ω–æ")
            else:
                st.warning(f"üéÆ GPU: {gpu_name}")
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏
            st.subheader("‚ÑπÔ∏è –û –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏")
            st.info(f"–í–µ—Ä—Å–∏—è: {Config.VERSION}")
            st.info(f"–ú–æ–¥–µ–ª—å: {Config.DIARIZATION_MODEL.split('/')[-1]}")
            st.info(f"–ú–∞–∫—Å. —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {Config.MAX_FILE_SIZE_MB} –ú–ë")
            st.info(f"–ß–∞—Å—Ç–æ—Ç–∞: {Config.PREFERRED_SAMPLE_RATE}Hz")
            st.info(f"–¢–∞–π–º–∫–æ–¥: SMPTE 59.94 DROP")
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞
            st.subheader("üéõÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞")
            
            # –ü—Ä–µ—Å–µ—Ç—ã –Ω–∞—Å—Ç—Ä–æ–µ–∫
            presets = Config.DiarizationTuning.get_presets()
            preset_names = list(presets.keys())
            
            selected_preset = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–µ—Å–µ—Ç:",
                preset_names,
                index=0,
                help="–ì–æ—Ç–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–ø–∏—Å–µ–π"
            )
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –ø—Ä–µ—Å–µ—Ç–∞
            if selected_preset:
                st.info(f"üìù {presets[selected_preset]['description']}")
            
            # –ö–Ω–æ–ø–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –ø—Ä–µ—Å–µ—Ç–∞
            if st.button("üéØ –ü—Ä–∏–º–µ–Ω–∏—Ç—å –ø—Ä–µ—Å–µ—Ç"):
                preset_values = presets[selected_preset]
                st.session_state.tuning_settings.update({
                    "vad_onset": preset_values["vad_onset"],
                    "vad_offset": preset_values["vad_offset"],
                    "seg_onset": preset_values["seg_onset"],
                    "seg_offset": preset_values["seg_offset"],
                    "clustering": preset_values["clustering"],
                })
                st.success(f"‚úÖ –ü—Ä–∏–º–µ–Ω—ë–Ω –ø—Ä–µ—Å–µ—Ç: {selected_preset}")
                st.rerun()
            
            # –î–µ—Ç–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ —ç–∫—Å–ø–∞–Ω–¥–µ—Ä–µ
            with st.expander("‚öôÔ∏è –î–µ—Ç–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏"):
                st.markdown("**üéôÔ∏è –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –≥–æ–ª–æ—Å–∞ (VAD)**")
                st.markdown("*–ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫ –Ω–∞—á–∞–ª—É –∏ –æ–∫–æ–Ω—á–∞–Ω–∏—é —Ä–µ—á–∏*")
                
                tuning_settings = st.session_state.tuning_settings
                
                # VAD –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
                vad_onset = st.slider(
                    "–ü–æ—Ä–æ–≥ –Ω–∞—á–∞–ª–∞ —Ä–µ—á–∏",
                    min_value=0.1, max_value=0.9, 
                    value=tuning_settings["vad_onset"],
                    step=0.05,
                    help="–ú–µ–Ω—å—à–µ = —É–ª–∞–≤–ª–∏–≤–∞–µ—Ç —Ç–∏—Ö–∏–µ –≥–æ–ª–æ—Å–∞, –±–æ–ª—å—à–µ = —Ç–æ–ª—å–∫–æ –≥—Ä–æ–º–∫–∏–µ",
                    key="vad_onset_slider"
                )
                
                vad_offset = st.slider(
                    "–ü–æ—Ä–æ–≥ –æ–∫–æ–Ω—á–∞–Ω–∏—è —Ä–µ—á–∏",
                    min_value=0.1, max_value=0.9,
                    value=tuning_settings["vad_offset"],
                    step=0.05,
                    help="–ú–µ–Ω—å—à–µ = –±—ã—Å—Ç—Ä–µ–µ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–Ω–µ—Ü —Ä–µ—á–∏",
                    key="vad_offset_slider"
                )
                
                st.markdown("**üìä –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è**")
                st.markdown("*–†–∞–∑–±–∏–≤–∫–∞ –∑–∞–ø–∏—Å–∏ –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã*")
                
                seg_onset = st.slider(
                    "–ü–æ—Ä–æ–≥ –Ω–∞—á–∞–ª–∞ —Å–µ–≥–º–µ–Ω—Ç–∞",
                    min_value=0.1, max_value=0.9,
                    value=tuning_settings["seg_onset"],
                    step=0.05,
                    help="–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫ —Å–º–µ–Ω–µ —Å–ø–∏–∫–µ—Ä–∞",
                    key="seg_onset_slider"
                )
                
                seg_offset = st.slider(
                    "–ü–æ—Ä–æ–≥ –æ–∫–æ–Ω—á–∞–Ω–∏—è —Å–µ–≥–º–µ–Ω—Ç–∞",
                    min_value=0.1, max_value=0.9,
                    value=tuning_settings["seg_offset"],
                    step=0.05,
                    help="–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω—Ü–∞ —Å–µ–≥–º–µ–Ω—Ç–∞",
                    key="seg_offset_slider"
                )
                
                st.markdown("**üë• –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Å–ø–∏–∫–µ—Ä–æ–≤**")
                st.markdown("*–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –≥–æ–ª–æ—Å–æ–≤*")
                
                clustering = st.slider(
                    "–ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Å–ø–∏–∫–µ—Ä–æ–≤",
                    min_value=0.1, max_value=0.9,
                    value=tuning_settings["clustering"],
                    step=0.05,
                    help="–ú–µ–Ω—å—à–µ = –±–æ–ª—å—à–µ —Å–ø–∏–∫–µ—Ä–æ–≤, –±–æ–ª—å—à–µ = –º–µ–Ω—å—à–µ —Å–ø–∏–∫–µ—Ä–æ–≤",
                    key="clustering_slider"
                )
                
                st.markdown("**üî¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤**")
                
                col1, col2 = st.columns(2)
                with col1:
                    min_speakers = st.number_input(
                        "–ú–∏–Ω–∏–º—É–º —Å–ø–∏–∫–µ—Ä–æ–≤",
                        min_value=1, max_value=20,
                        value=tuning_settings["min_speakers"] if tuning_settings["min_speakers"] else 1,
                        help="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–∏–Ω–∏–º—É–º —Å–ø–∏–∫–µ—Ä–æ–≤",
                        key="min_speakers_input"
                    )
                    if min_speakers == 1:
                        min_speakers = None
                
                with col2:
                    max_speakers = st.number_input(
                        "–ú–∞–∫—Å–∏–º—É–º —Å–ø–∏–∫–µ—Ä–æ–≤",
                        min_value=2, max_value=20,
                        value=tuning_settings["max_speakers"] if tuning_settings["max_speakers"] else 10,
                        help="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–∞–∫—Å–∏–º—É–º —Å–ø–∏–∫–µ—Ä–æ–≤",
                        key="max_speakers_input"
                    )
                    if max_speakers == 10:
                        max_speakers = None
                
                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏
                new_settings = {
                    "vad_onset": vad_onset,
                    "vad_offset": vad_offset,
                    "seg_onset": seg_onset,
                    "seg_offset": seg_offset,
                    "clustering": clustering,
                    "min_speakers": min_speakers,
                    "max_speakers": max_speakers,
                }
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ session_state
                st.session_state.tuning_settings = new_settings
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º, —á—Ç–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑–º–µ–Ω–µ–Ω—ã
                if new_settings != tuning_settings:
                    st.success("‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã - –±—É–¥—É—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω—ã –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º –∞–Ω–∞–ª–∏–∑–µ")
                
                # –ö–Ω–æ–ø–∫–∞ —Å–±—Ä–æ—Å–∞ –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º
                if st.button("üîÑ –°–±—Ä–æ—Å–∏—Ç—å –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º"):
                    st.session_state.tuning_settings = {
                        "vad_onset": 0.5,
                        "vad_offset": 0.35,
                        "seg_onset": 0.5,
                        "seg_offset": 0.5,
                        "clustering": 0.7154,
                        "min_speakers": None,
                        "max_speakers": None,
                    }
                    st.success("‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–±—Ä–æ—à–µ–Ω—ã –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º")
                    st.rerun()
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            st.subheader("‚ö° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
            st.markdown(f"""
            **–î–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:**
            - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ WAV —Ñ–∞–π–ª—ã —Å —á–∞—Å—Ç–æ—Ç–æ–π {Config.PREFERRED_SAMPLE_RATE}Hz (–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ)
            - 32kHz —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ —Å –º–æ–¥–µ–ª—å—é
            - –§–∞–π–ª—ã –¥–æ 100 –ú–ë –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –±—ã—Å—Ç—Ä–µ–µ
            - GPU –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤ ~10-20 —Ä–∞–∑ –±—ã—Å—Ç—Ä–µ–µ CPU
            
            **–§–∞–π–Ω—Ç—é–Ω–∏–Ω–≥ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:**
            - **–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –≥–æ–ª–æ—Å–∞?** ‚Üí –ü—Ä–µ—Å–µ—Ç "–í—ã—Å–æ–∫–∞—è —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"
            - **–ú–Ω–æ–≥–æ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π?** ‚Üí –ü—Ä–µ—Å–µ—Ç "–ù–∏–∑–∫–∞—è —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"
            - **–®—É–º–Ω–∞—è –∑–∞–ø–∏—Å—å?** ‚Üí –ü—Ä–µ—Å–µ—Ç "–®—É–º–Ω–∞—è –∑–∞–ø–∏—Å—å"
            - **–ú–Ω–æ–≥–æ —Å–ø–∏–∫–µ—Ä–æ–≤ (5+)?** ‚Üí –ü—Ä–µ—Å–µ—Ç "–ú–Ω–æ–≥–æ —Å–ø–∏–∫–µ—Ä–æ–≤"
            - **–ú–∞–ª–æ —Å–ø–∏–∫–µ—Ä–æ–≤ (2-3)?** ‚Üí –ü—Ä–µ—Å–µ—Ç "–ú–∞–ª–æ —Å–ø–∏–∫–µ—Ä–æ–≤"
            
            **–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ—Ä–æ–≥–æ–≤:**
            - **VAD Onset ‚Üì** = —É–ª–∞–≤–ª–∏–≤–∞–µ—Ç —Ç–∏—Ö–∏–µ –≥–æ–ª–æ—Å–∞
            - **VAD Offset ‚Üì** = –±—ã—Å—Ç—Ä–µ–µ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–Ω–µ—Ü —Ä–µ—á–∏
            - **Clustering ‚Üì** = —Å–æ–∑–¥–∞–µ—Ç –±–æ–ª—å—à–µ —Å–ø–∏–∫–µ—Ä–æ–≤
            - **Clustering ‚Üë** = –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø–æ—Ö–æ–∂–∏–µ –≥–æ–ª–æ—Å–∞
            
            **–¢–∞–π–º–∫–æ–¥—ã:**
            - –§–æ—Ä–º–∞—Ç: SMPTE 59.94 Drop Frame
            - –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏: —Ç–æ—á–∫–∞ —Å –∑–∞–ø—è—Ç–æ–π (;)
            - –ü—Ä–∏–º–µ—Ä: 00;40;31;16
            
            **–≠–∫—Å–ø–æ—Ä—Ç:**
            - CSV: —Ñ–æ—Ä–º–∞—Ç Adobe Audition –º–∞—Ä–∫–µ—Ä–æ–≤
            - –ù–∞–∑–≤–∞–Ω–∏—è: Voice_01, Voice_02, –∏ —Ç.–¥.
            """)
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
            temp_dir = Path("temp")
            if temp_dir.exists():
                temp_files = list(temp_dir.glob("*"))
                if temp_files:
                    st.info(f"üìÅ –í—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(temp_files)}")
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                    total_size = sum(f.stat().st_size for f in temp_files if f.is_file())
                    st.info(f"üìä –†–∞–∑–º–µ—Ä: {total_size / (1024*1024):.1f} –ú–ë")
                    st.caption("üí° –§–∞–π–ª—ã —Å—Ç–∞—Ä—à–µ 1 —á–∞—Å–∞ —É–¥–∞–ª—è—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
            
            # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            if st.button("üßπ –û—á–∏—Å—Ç–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã"):
                if temp_dir.exists():
                    try:
                        shutil.rmtree(temp_dir)
                        st.success("‚úÖ –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –æ—á–∏—â–µ–Ω—ã")
                        st.rerun()
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ: {str(e)}")
                else:
                    st.info("‚ÑπÔ∏è –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        # –û—Å–Ω–æ–≤–Ω–∞—è –æ–±–ª–∞—Å—Ç—å
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.header("üìÅ –í—ã–±—Ä–∞–Ω–Ω—ã–π —Ñ–∞–π–ª")
            if selected_file and file_path:
                file_size_mb = os.path.getsize(file_path) / (1024*1024)
                st.info(f"üìÑ –§–∞–π–ª: {selected_file}")
                st.info(f"üìä –†–∞–∑–º–µ—Ä: {file_size_mb:.2f} MB")
                st.info(f"üìç –ü—É—Ç—å: {file_path}")
                
                # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–∞—Ö
                if file_size_mb > 100:
                    st.warning(f"‚ö†Ô∏è –ë–æ–ª—å—à–æ–π —Ñ–∞–π–ª ({file_size_mb:.1f} –ú–ë) –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏!")
                    estimated_time = max(1, int(file_size_mb * 0.5))
                    st.info(f"‚è±Ô∏è –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {estimated_time} –º–∏–Ω—É—Ç")
                
                # –ö–Ω–æ–ø–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
                if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é", type="primary"):
                    if not self.initialize_pipeline():
                        return
                    
                    self.df_results_original = self.process_audio_file(str(file_path))
                    
                    if self.df_results_original is not None:
                        # –ü–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ—Å—á–µ—Ç —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º —Ç–∞–π–º–∫–æ–¥–æ–º
                        self.recalculate_timecodes()
                        st.success("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
            else:
                st.info("üëà –í—ã–±–µ—Ä–∏—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é
                st.markdown("""
                ### üìã –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é:
                
                1. **–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª** –æ–¥–Ω–∏–º –∏–∑ —Å–ø–æ—Å–æ–±–æ–≤:
                   - üìÅ –ù–∞–∂–º–∏—Ç–µ "Browse files" –∏ –≤—ã–±–µ—Ä–∏—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª
                   - üóÇÔ∏è –ò–ª–∏ –≤–≤–µ–¥–∏—Ç–µ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤—Ä—É—á–Ω—É—é
                
                2. **–ù–∞—Å—Ç—Ä–æ–π—Ç–µ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥** (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ):
                   - üéõÔ∏è –í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–µ—Å–µ—Ç –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏
                   - ‚öôÔ∏è –ò–ª–∏ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –¥–µ—Ç–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                   - üéØ –î–ª—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –≥–æ–ª–æ—Å–æ–≤: "–í—ã—Å–æ–∫–∞—è —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å"
                
                3. **–ù–∞–∂–º–∏—Ç–µ "–ó–∞–ø—É—Å—Ç–∏—Ç—å –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é"** –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
                
                4. **–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –Ω–∞—á–∞–ª—å–Ω—ã–π —Ç–∞–π–º–∫–æ–¥** –≤ —Ä–∞–∑–¥–µ–ª–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
                   - –§–æ—Ä–º–∞—Ç: HH;MM;SS;FF (–Ω–∞–ø—Ä–∏–º–µ—Ä: 00;40;31;16)
                   - –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø–µ—Ä–µ—Å—á–µ—Ç–∞
                
                5. **–ò–∑—É—á–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã** —Å —Ç–∞–π–º–∫–æ–¥–∞–º–∏ SMPTE
                
                6. **–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã** –≤ Adobe Audition —Ñ–æ—Ä–º–∞—Ç–µ
                
                ### üéõÔ∏è –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º —Å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ–º:
                
                - **–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —Ç–∏—Ö–∏–µ –≥–æ–ª–æ—Å–∞?** ‚Üí –£–º–µ–Ω—å—à–∏—Ç–µ VAD Onset –¥–æ 0.2-0.3
                - **–ú–Ω–æ–≥–æ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π?** ‚Üí –£–≤–µ–ª–∏—á—å—Ç–µ VAD Onset –¥–æ 0.7-0.8
                - **–ù–µ –≤—Å–µ —Å–ø–∏–∫–µ—Ä—ã –Ω–∞–π–¥–µ–Ω—ã?** ‚Üí –£–º–µ–Ω—å—à–∏—Ç–µ Clustering –¥–æ 0.5-0.6
                - **–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Å–ø–∏–∫–µ—Ä–æ–≤?** ‚Üí –£–≤–µ–ª–∏—á—å—Ç–µ Clustering –¥–æ 0.8-0.9
                - **–®—É–º–Ω–∞—è –∑–∞–ø–∏—Å—å?** ‚Üí –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–µ—Å–µ—Ç "–®—É–º–Ω–∞—è –∑–∞–ø–∏—Å—å"
                
                ---
                
                **–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:** {formats}
                
                **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä:** {max_size} –ú–ë
                """.format(
                    formats=", ".join([f.upper() for f in Config.SUPPORTED_AUDIO_FORMATS]),
                    max_size=Config.MAX_FILE_SIZE_MB
                ))
        
        with col2:
            st.header("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
            if self.df_results_original is not None:
                total_segments = len(self.df_results_original)
                total_speakers = self.df_results_original['Speaker'].nunique()
                total_duration = self.df_results_original['Duration (sec)'].sum()
                
                st.metric("–°–µ–≥–º–µ–Ω—Ç–æ–≤", total_segments)
                st.metric("–°–ø–∏–∫–µ—Ä–æ–≤", total_speakers)
                st.metric("–û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å", f"{total_duration:.1f}—Å")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞
                st.subheader("üéõÔ∏è –¢–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏")
                tuning = st.session_state.tuning_settings
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–æ–π –ø—Ä–µ—Å–µ—Ç –±–ª–∏–∂–µ –≤—Å–µ–≥–æ –∫ —Ç–µ–∫—É—â–∏–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º
                presets = Config.DiarizationTuning.get_presets()
                current_preset = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ"
                for preset_name, preset_values in presets.items():
                    if (abs(tuning["vad_onset"] - preset_values["vad_onset"]) < 0.01 and
                        abs(tuning["vad_offset"] - preset_values["vad_offset"]) < 0.01 and
                        abs(tuning["clustering"] - preset_values["clustering"]) < 0.01):
                        current_preset = preset_name
                        break
                
                st.info(f"üéØ –ü—Ä–µ—Å–µ—Ç: {current_preset}")
                st.info(f"üéôÔ∏è VAD: {tuning['vad_onset']:.2f} / {tuning['vad_offset']:.2f}")
                st.info(f"üìä –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è: {tuning['seg_onset']:.2f} / {tuning['seg_offset']:.2f}")
                st.info(f"üë• –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è: {tuning['clustering']:.3f}")
                
                if tuning["min_speakers"] or tuning["max_speakers"]:
                    speakers_range = f"{tuning['min_speakers'] or '?'}-{tuning['max_speakers'] or '?'}"
                    st.info(f"üî¢ –°–ø–∏–∫–µ—Ä–æ–≤: {speakers_range}")
            else:
                st.info("üîÑ –ó–∞–ø—É—Å—Ç–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–∞–∂–µ –±–µ–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                st.subheader("üéõÔ∏è –ì–æ—Ç–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏")
                tuning = st.session_state.tuning_settings
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–∫—É—â–∏–π –ø—Ä–µ—Å–µ—Ç
                presets = Config.DiarizationTuning.get_presets()
                current_preset = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ"
                for preset_name, preset_values in presets.items():
                    if (abs(tuning["vad_onset"] - preset_values["vad_onset"]) < 0.01 and
                        abs(tuning["vad_offset"] - preset_values["vad_offset"]) < 0.01 and
                        abs(tuning["clustering"] - preset_values["clustering"]) < 0.01):
                        current_preset = preset_name
                        break
                
                st.info(f"üéØ –ü—Ä–µ—Å–µ—Ç: {current_preset}")
                st.info(f"üéôÔ∏è VAD: {tuning['vad_onset']:.2f} / {tuning['vad_offset']:.2f}")
                st.info(f"üìä –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è: {tuning['seg_onset']:.2f} / {tuning['seg_offset']:.2f}")
                st.info(f"üë• –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è: {tuning['clustering']:.3f}")
                
                if tuning["min_speakers"] or tuning["max_speakers"]:
                    speakers_range = f"{tuning['min_speakers'] or '?'}-{tuning['max_speakers'] or '?'}"
                    st.info(f"üî¢ –°–ø–∏–∫–µ—Ä–æ–≤: {speakers_range}")
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if self.df_results_original is not None:
            st.header("üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏")
            
            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Å–ø–∏–∫–µ—Ä–∞–º
            col1, col2 = st.columns([1, 3])
            
            with col1:
                st.subheader("–§–∏–ª—å—Ç—Ä —Å–ø–∏–∫–µ—Ä–æ–≤")
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º df_results –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ df_results_original
                display_df = self.df_results if self.df_results is not None else self.df_results_original
                speakers = display_df['Speaker'].unique()
                
                # –ß–µ–∫–±–æ–∫—Å "–í—Å–µ —Å–ø–∏–∫–µ—Ä—ã"
                all_speakers = st.checkbox("–í—Å–µ —Å–ø–∏–∫–µ—Ä—ã", value=True)
                
                if all_speakers:
                    selected_speakers = list(speakers)
                else:
                    selected_speakers = []
                    for speaker in speakers:
                        if st.checkbox(f"–°–ø–∏–∫–µ—Ä {speaker}", value=False):
                            selected_speakers.append(speaker)
                
                if not selected_speakers:
                    selected_speakers = list(speakers)
            
            with col2:
                # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–∞–π–º–∫–æ–¥–∞
                st.subheader("üïê –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–∞–π–º–∫–æ–¥–∞")
                st.markdown("**SMPTE 59.94 Drop Frame**")
                
                timecode_input = st.text_input(
                    "–ù–∞—á–∞–ª—å–Ω—ã–π —Ç–∞–π–º–∫–æ–¥ (HH;MM;SS;FF)",
                    value=self.start_timecode,
                    placeholder="00;40;31;16",
                    help="–í–≤–µ–¥–∏—Ç–µ –Ω–∞—á–∞–ª—å–Ω—ã–π —Ç–∞–π–º–∫–æ–¥ —Å –≤–∞—à–µ–≥–æ —Ç–∞–π–º–ª–∞–π–Ω–∞ –∏ –Ω–∞–∂–º–∏—Ç–µ Enter"
                )
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç–∞–π–º–∫–æ–¥–∞
                if timecode_input != self.start_timecode:
                    if SMPTETimeCode.validate_timecode(timecode_input):
                        self.start_timecode = timecode_input
                        if self.recalculate_timecodes():
                            st.success(f"‚úÖ –¢–∞–π–º–∫–æ–¥—ã –ø–µ—Ä–µ—Å—á–∏—Ç–∞–Ω—ã: {self.start_timecode}")
                    else:
                        st.error("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ç–∞–π–º–∫–æ–¥–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ HH;MM;SS;FF")
                
                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
                display_df = self.df_results if self.df_results is not None else self.df_results_original
                filtered_df = display_df[
                    display_df['Speaker'].isin(selected_speakers)
                ].copy()
                
                # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
                if self.df_results is not None:
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å SMPTE —Ç–∞–π–º–∫–æ–¥–∞–º–∏
                    table_df = filtered_df[['Speaker', 'Start (SMPTE)', 'End (SMPTE)', 'Duration (sec)']].copy()
                    table_df = table_df.rename(columns={
                        'Start (SMPTE)': 'Start Timecode',
                        'End (SMPTE)': 'End Timecode',
                        'Duration (sec)': 'Duration (sec)'
                    })
                else:
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥—ã
                    table_df = filtered_df[['Speaker', 'Start (sec)', 'End (sec)', 'Duration (sec)']].copy()
                
                st.subheader("–¢–∞–±–ª–∏—Ü–∞ —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
                st.dataframe(
                    table_df,
                    use_container_width=True,
                    hide_index=True
                )
                
                # –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –ø–µ—Ä–µ—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
                if self.df_results is not None:
                    st.subheader("üì• –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                    col_exp1, col_exp2 = st.columns(2)
                    
                    with col_exp1:
                        if st.button("–≠–∫—Å–ø–æ—Ä—Ç –≤ CSV (Adobe Audition)"):
                            output_filename = Config.get_output_filename(selected_file, "csv")
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–ø–∫—É —Å –∏—Å—Ö–æ–¥–Ω—ã–º —Ñ–∞–π–ª–æ–º –∏–ª–∏ –≤ —Ç–µ–∫—É—â—É—é –ø–∞–ø–∫—É
                            if file_path and os.path.dirname(str(file_path)) != "temp":
                                output_dir = os.path.dirname(str(file_path))
                            else:
                                output_dir = os.getcwd()
                            output_path = os.path.join(output_dir, output_filename)
                            
                            if self.export_results(filtered_df, output_path, "csv"):
                                st.success(f"‚úÖ Adobe Audition –º–∞—Ä–∫–µ—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_path}")
                                
                                # –ö–Ω–æ–ø–∫–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                                with open(output_path, "rb") as f:
                                    st.download_button(
                                        label="üì• –°–∫–∞—á–∞—Ç—å CSV",
                                        data=f.read(),
                                        file_name=output_filename,
                                        mime="text/csv"
                                    )
                    
                    with col_exp2:
                        if st.button("–≠–∫—Å–ø–æ—Ä—Ç –≤ Excel"):
                            output_filename = Config.get_output_filename(selected_file, "excel")
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–ø–∫—É —Å –∏—Å—Ö–æ–¥–Ω—ã–º —Ñ–∞–π–ª–æ–º –∏–ª–∏ –≤ —Ç–µ–∫—É—â—É—é –ø–∞–ø–∫—É
                            if file_path and os.path.dirname(str(file_path)) != "temp":
                                output_dir = os.path.dirname(str(file_path))
                            else:
                                output_dir = os.getcwd()
                            output_path = os.path.join(output_dir, output_filename)
                            
                            if self.export_results(filtered_df, output_path, "excel"):
                                st.success(f"‚úÖ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
                                
                                # –ö–Ω–æ–ø–∫–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
                                with open(output_path, "rb") as f:
                                    st.download_button(
                                        label="üì• –°–∫–∞—á–∞—Ç—å Excel",
                                        data=f.read(),
                                        file_name=output_filename,
                                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                    )
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –ø–µ—Ä–µ—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
            if self.df_results is not None:
                st.header("üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è")
                fig = self.create_timeline_visualization(filtered_df)
                st.plotly_chart(fig, use_container_width=True)
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                st.header("üìã –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
                speaker_stats = filtered_df.groupby('Speaker').agg({
                    'Duration (sec)': ['sum', 'mean', 'count']
                }).round(2)
                
                speaker_stats.columns = ['–û–±—â–µ–µ –≤—Ä–µ–º—è (—Å)', '–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è (—Å)', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤']
                st.dataframe(speaker_stats, use_container_width=True)

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
if __name__ == "__main__":
    app = AudioDiarizationApp()
    app.run() 